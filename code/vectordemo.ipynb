{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search in Python (Azure AI Search)\n",
    "\n",
    "This notebook demonstrates the basic understanding of Vector Search. We will look into Cosine Similarity, Text Search, and Vector Search examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "- An Azure subscription, with access to Azure OpenAI. You must have the Azure OpenAI service name and an API key.\n",
    "- Azure AI Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create Python Virtual Environment\n",
    "\n",
    "- run in terminal ` python -m venv <your-virtual-env-name> `\n",
    "- activate the virtual environment ( for Powershell terminal) `<your-virtual-env-name>\\Scripts\\Activate.ps1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update  environment File\n",
    "\n",
    "rename the file `.env.example` to `.env` and fill the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication to OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import json\n",
    "import os\n",
    "# Set up OpenAI client based on environment variables\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_KEY\", \"\")) > 0 else None\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "embedding_model_name = os.getenv(\"AZURE_OPENAI_ADA002_EMBEDDING_DEPLOYMENT\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "\n",
    "\n",
    "openai_credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(openai_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_deployment=azure_openai_embedding_deployment,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_version=azure_openai_api_version,\n",
    "    api_key=azure_openai_key,\n",
    "    azure_ad_token_provider=token_provider if not azure_openai_key else None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the embedding for a word\n",
    "\n",
    "**Dimension of a vector 1536**\n",
    "\n",
    "[text-embedding-ada-002](https://openai.com/index/new-and-improved-embedding-model/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"automobile\"\n",
    "response = client.embeddings.create(model=embedding_model_name, input=sentence)\n",
    "vector = response.data[0].embedding\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets look into the Vector Similarity Technique ( Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog. \t\t A fast brown fox leaps over a sleepy dog. \t\t Score: 0.9470\n",
      "I love programming in Python. \t\t Coding in Python is enjoyable. \t\t Score: 0.9236\n",
      "Artificial intelligence is fascinating. \t\t aaandmas \t\t Score: 0.7496\n"
     ]
    }
   ],
   "source": [
    "#Cosine Similarity\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "sentence1 = ['The quick brown fox jumps over the lazy dog.',\n",
    "              'I love programming in Python.',\n",
    "              'Artificial intelligence is fascinating.'\n",
    "              ]\n",
    "\n",
    "sentence2 = ['A fast brown fox leaps over a sleepy dog.',\n",
    "              'Coding in Python is enjoyable.',\n",
    "              'aaandmas'\n",
    "              ]\n",
    "\n",
    "def get_embeddings(sentences):\n",
    "    embeddings_response = client.embeddings.create(model=embedding_model_name, input=sentences)\n",
    "    return [embedding_object.embedding for embedding_object in embeddings_response.data]\n",
    "\n",
    "embeddings1 = get_embeddings(sentence1)\n",
    "embeddings2 = get_embeddings(sentence2)\n",
    "\n",
    "for i in range(len(sentence1)):\n",
    "    print(f\"{sentence1[i]} \\t\\t {sentence2[i]} \\t\\t Score: {cosine_similarity(embeddings1[i], embeddings2[i]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input file and creating the Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file code\\data\\azure_products-documents.json\n",
    "\n",
    "with open('data/azure_products-documents.json') as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "# take the first 5 element from the input_data\n",
    "\n",
    "# input_data = input_data[:5]\n",
    "\n",
    "\n",
    "output_data = []\n",
    "for i in input_data:\n",
    "    output = {}\n",
    "    content_embedding = client.embeddings.create(model=embedding_model_name, input= i['content']).data[0].embedding\n",
    "    \n",
    "    output['id']  = i['id']\n",
    "    output['title'] = i['title']\n",
    "    output['content'] = i['content']\n",
    "    output['category'] = i['category']\n",
    "    output['contentVector'] = content_embedding\n",
    "    output_data.append(output)\n",
    "\n",
    "# export the Output data\n",
    "\n",
    "with open('data/azure_products-documents-output.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_products created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchFieldDataType,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndex,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_endpoint, credential=DefaultAzureCredential())\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, retrievable =True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
    "                    filterable=True),\n",
    "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"myHnsw\"\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"myHnswProfile\",\n",
    "            algorithm_configuration_name=\"myHnsw\",\n",
    "            vectorizer_name=\"myVectorizer\"\n",
    "        )\n",
    "    ],\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"myVectorizer\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=azure_openai_endpoint,\n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=embedding_model_name,\n",
    "                api_key=azure_openai_key\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# semantic_config = SemanticConfiguration(\n",
    "#     name=\"my-semantic-config\",\n",
    "#     prioritized_fields=SemanticPrioritizedFields(\n",
    "#         title_field=SemanticField(field_name=\"title\"),\n",
    "#         keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "#         content_fields=[SemanticField(field_name=\"content\")]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Create the semantic settings with the configuration\n",
    "# semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=\"azure_products\", fields=fields,\n",
    "                    vector_search=vector_search)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f'{result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert text and embeddings into vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 216 documents\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "import json\n",
    "\n",
    "# Upload some documents to the index\n",
    "output_path = os.path.join('data', 'azure_products-documents-output.json')\n",
    "output_directory = os.path.dirname(output_path)\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "with open(output_path, 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=\"azure_products\", credential=DefaultAzureCredential())\n",
    "result = search_client.upload_documents(documents)\n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Event Hubs Big Data 0.031159421429038048\n",
      "Azure Data Explorer Analytics 0.03053613007068634\n",
      "Azure Queue Storage Storage 0.029957523569464684\n",
      "Azure Event Grid Integration 0.029726775363087654\n",
      "Azure Batch Compute 0.02943722903728485\n",
      "Azure HDInsight Analytics 0.028594771400094032\n",
      "Azure Database for PostgreSQL Databases 0.027756938710808754\n",
      "Azure Cache for Redis Databases 0.02698412910103798\n",
      "Azure Database for MariaDB Databases 0.025925926864147186\n",
      "Azure Data Factory Analytics 0.025653595104813576\n"
     ]
    }
   ],
   "source": [
    "### Vector Query\n",
    "\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = client.embeddings.create(model=embedding_model_name, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"azure_products\"\n",
    "search_client = SearchClient(search_endpoint, AZURE_SEARCH_FULL_INDEX,\n",
    "                             credential=DefaultAzureCredential())\n",
    "\n",
    "\n",
    "search_query = \"Suggest product for sending large events\"\n",
    "search_vector = get_embedding(search_query)\n",
    "r = search_client.search(search_query, top=10, vector_queries=[\n",
    "    VectorizedQuery(vector=search_vector, k_nearest_neighbors=50, fields=\"contentVector\")\n",
    "])\n",
    "\n",
    "\n",
    "for doc in r:\n",
    "    print(doc['title'], doc['category'], doc['@search.score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Database for MariaDB Databases 3.7918355\n",
      "Azure DevOps Developer Tools 3.5862749\n",
      "Azure Database for PostgreSQL Databases 3.4531152\n",
      "Azure Cache for Redis Databases 3.14085\n",
      "Azure Database for MySQL Databases 3.14085\n",
      "Azure API for FHIR Healthcare 3.14085\n",
      "Azure Data Explorer Analytics 2.7688813\n",
      "Azure Kubernetes Service (AKS) Containers 2.6856306\n",
      "Azure HDInsight Analytics 2.6012852\n",
      "Azure Event Hubs Big Data 2.3468874\n",
      "Azure Batch Compute 2.080144\n",
      "Azure Queue Storage Storage 1.9562218\n",
      "Azure Data Factory Analytics 1.8540324\n",
      "Azure App Service Web 1.8125224\n",
      "Azure Table Storage Storage 1.5812824\n",
      "Azure Event Grid Integration 1.4575477\n",
      "Azure Machine Learning AI + Machine Learning 1.3710604\n",
      "Azure Databricks Analytics 1.3292837\n",
      "Azure HPC Cache Storage 1.1963742\n",
      "Azure Data Bricks Analytics 1.1963742\n",
      "Azure Synapse Analytics Analytics 1.1717747\n",
      "Azure Key Vault Security 1.1683216\n",
      "Azure Bot Service AI + Machine Learning 1.1683216\n",
      "Azure Databricks Analytics 1.1075262\n",
      "Azure Logic Apps Integration 1.1075262\n",
      "Azure Storage Storage 0.9377467\n",
      "Azure Functions Compute 0.9377467\n",
      "Azure Data Lake Storage Storage 0.9377467\n",
      "Azure Front Door Networking 0.8893397\n",
      "Azure Batch AI AI + Machine Learning 0.8893397\n",
      "Azure API Management Integration 0.80597496\n",
      "Azure Managed Disks Storage 0.79185283\n",
      "Azure Blob Storage Storage 0.79185283\n",
      "Azure Virtual Machines Compute 0.7024957\n",
      "Azure Cosmos DB Databases 0.6911987\n",
      "Azure Cognitive Search AI + Machine Learning 0.6911987\n",
      "Azure Active Directory Identity 0.6911987\n"
     ]
    }
   ],
   "source": [
    "#Normal Search\n",
    "\n",
    "r = search_client.search(search_query) \n",
    "for doc in r:\n",
    "    print(doc['title'], doc['category'], doc['@search.score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azaisearchragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
